{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T06:51:40.832906Z",
     "start_time": "2020-09-17T06:51:35.810465Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy \n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm,trange\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "\n",
    "os.chdir(\"../../\")\n",
    "root_path = os.getcwd()\n",
    "\n",
    "raw_file_path = os.path.join(root_path, \"Bigcon2020_raw_file\")\n",
    "csv_file_path = os.path.join(root_path, \"BigCon_2020/csv_files\")\n",
    "pickle_file_path = os.path.join(root_path, \"BigCon_2020/pickle_files\")\n",
    "image_path = 'C:/Users/rears/OneDrive/바탕 화면/dacon_covid19/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T06:51:52.724444Z",
     "start_time": "2020-09-17T06:51:52.721489Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 필요파일\n",
    "    * 인접 행정동, 행정동간 거리 파일\n",
    "    * 행정동별 생활인구 파일 \n",
    "    * 행정동별 교통편의성 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T06:51:56.508508Z",
     "start_time": "2020-09-17T06:51:56.481602Z"
    }
   },
   "outputs": [],
   "source": [
    "distance_file=[pd.read_csv(os.path.join(csv_file_path,file), index_col=[0]) for file in os.listdir(csv_file_path) if file.startswith('distance')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T06:51:57.440142Z",
     "start_time": "2020-09-17T06:51:57.424476Z"
    }
   },
   "outputs": [],
   "source": [
    "real_dist = distance_file[0]\n",
    "adjacent_dist = distance_file[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T06:51:57.933640Z",
     "start_time": "2020-09-17T06:51:57.921672Z"
    }
   },
   "outputs": [],
   "source": [
    "living_population=pd.read_csv(os.path.join(csv_file_path,'CTGG_HDNG_FLOW.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T12:10:16.521618Z",
     "start_time": "2020-09-17T12:10:16.515624Z"
    }
   },
   "outputs": [],
   "source": [
    "floating_population=pd.read_csv(os.path.join(csv_file_path,'CTGG_HDNG_POP.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T11:09:47.323383Z",
     "start_time": "2020-09-17T11:09:47.312413Z"
    }
   },
   "outputs": [],
   "source": [
    "convenience_index = pd.read_csv(os.path.join(csv_file_path, 'conv_index_df.csv'), index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T05:44:13.965598Z",
     "start_time": "2020-09-16T05:44:13.957594Z"
    }
   },
   "outputs": [],
   "source": [
    "# bus_route_num_dtd = pd.read_csv(os.path.join(csv_file_path,\"bus_route_num_dtd.csv\"), index_col=[0])\n",
    "\n",
    "# living_population.sample(10)\n",
    "\n",
    "# convenience_index = pd.read_csv(os.path.join(csv_file_path,'conv_index.csv'))\n",
    "\n",
    "# convenience_index.loc[:,'conv']=np.sqrt(convenience_index.conv)\n",
    "# living_population.loc[:,'value'] = np.sqrt(living_population.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCLP MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "$\\underset{h \\subset H}{\\operatorname{argmax}} (\\sum_{h^* \\in h} L(h^*) + C(h^*) \\cdot adjL(h^*))$ \n",
    "\n",
    "$L(h^*) : h^*$행정동의 생활인구 제곱근  \n",
    "$C(h^*) : h^*$행정동의 교통편의성 지수 제곱근   \n",
    "$adjL(h^*): h^*$행정동의 인접행정동들의 생활인구합 제곱근   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T11:23:47.046767Z",
     "start_time": "2020-09-17T11:23:47.039787Z"
    }
   },
   "source": [
    "___\n",
    "**Modified Version**\n",
    "\n",
    "$C_{n,n} \\circ W_{n,n} \\circ L_{n,1}\\ , n= number\\ of\\ dongs$  \n",
    "  \n",
    "___\n",
    "$C_{n,n} = \\{c_{i,j}\\}\\ s.t\\ \\ c_{i,j}= \\begin{cases}\n",
    "conv\\_in(i,j) & \\text{if $i=j$} \\\\\n",
    "conv\\_out(i,j) & \\text{if $i \\ne j$}\n",
    "\\end{cases}\\ , 1 \\le i,j \\le n$\n",
    "\n",
    "$L_{n,1}^{(1)} = \\{l_{i,1} :=\\ living\\ population\\ of\\ dong_i\\}, 1 \\le i \\le n $  \n",
    "$L_{n,1}^{(2)} = \\{l_{i,1} :=\\ living\\ population\\ of\\ dong_i\\}, 1 \\le i \\le n $\n",
    "\n",
    "\n",
    "$ Double\\ Power\\ Distance\\ Weights $  \n",
    "$D_{n,n} = \\{d_{i,j}\\} \\ s.t\\ \\ d_{i,j}= \\begin{cases}\n",
    "\\left (1-\\left (Dist(h_i,h_j) \\over d \\right)^2 \\right )^2 & \\text{if $0 \\le Dist(h_i,h_j) \\le d $} \\\\\n",
    "0 & \\text{if $Dist(h_i,h_j) > d$}\\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$W_{n,n}^{(k)} = \\{w_{i,j}^{(k)}\\}\\ s.t\\ \\  w_{i,j}^{(k)} = \\begin{cases}\n",
    "w_{i,j}^{(k-1)} \\cdot \\left (1-D_{h^{(k-1)},j} \\right) & \\text{if $i=j$}\\\\\n",
    "0 & \\text{if $i \\ne j$}\\end{cases}\\ \\ where \\ h^{(k-1)}:selected\\ dong\\ in \\ (k-1)th\\ MCLP\\ process$  \n",
    "$\\ (If\\ k=1, W_{n,n}^{(k)} = I_{n,n})$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T06:52:06.293156Z",
     "start_time": "2020-09-17T06:52:06.288206Z"
    }
   },
   "outputs": [],
   "source": [
    "# 거리별 가중치 계산\n",
    "def double_power_distance_weight(df, distance):\n",
    "    shape = df.shape\n",
    "    names = df.columns.tolist()\n",
    "    flatten_values = np.concatenate(df.values)\n",
    "    weights = np.array([(1-(dist/distance)**2) if dist < distance else 0 for dist in flatten_values])\n",
    "    weights_df = pd.DataFrame(weights.reshape(shape), columns = names)\n",
    "    weights_df.index = names\n",
    "    return weights_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T07:39:02.189359Z",
     "start_time": "2020-09-17T07:39:02.184405Z"
    }
   },
   "outputs": [],
   "source": [
    "def double_power_distance_weight(df=real_dist, distance=3000):\n",
    "    shape = df.shape\n",
    "    names = df.columns.tolist()\n",
    "    flatten_values = np.concatenate(df.values)\n",
    "    weights = np.array([(1-(dist/distance)**2) if dist < distance else 0 for dist in flatten_values])\n",
    "    weights_df = pd.DataFrame(weights.reshape(shape), columns = names)\n",
    "    weights_df.index = names\n",
    "    return weights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T07:42:42.080946Z",
     "start_time": "2020-09-17T07:42:42.076957Z"
    }
   },
   "outputs": [],
   "source": [
    "HDONG_ORDER = convenience_index.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T02:32:49.514377Z",
     "start_time": "2020-09-18T02:32:49.494430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef MCLP(dist_file, population_file, convenience_file, N=4, covid_class='A', Ages='3059', distance=3000,w1=.6,w2=.4):\\n    \\n    HDONG_ORDER = convenience_file.index.tolist()\\n    \\n    def double_power_distance_weight(df=dist_file, distance=distance):\\n        shape = df.shape\\n        names = df.columns.tolist()\\n        flatten_values = np.concatenate(df.values)\\n        weights = np.array([(1-(dist/distance)**2) if dist < distance else 0 for dist in flatten_values])\\n        weights_df = pd.DataFrame(weights.reshape(shape), columns = names)\\n        weights_df.index = names\\n        return weights_df\\n\\n    def update_weight_matrix(hdong=None, weight_matrix=None, HDONG_ORDER=HDONG_ORDER):\\n        shape=(34,34)\\n        if not isinstance(weight_matrix, np.ndarray):\\n            weight_matrix = np.diag(np.ones((34,)))\\n            return weight_matrix\\n        else:\\n            if hdong not in HDONG_ORDER:\\n                raise ValueError('hdong must be in HDONG_ORDER')\\n            \\n            updated_weight_matrix = weight_matrix*(1-double_power_distance_weight().loc[hdong].values)\\n            # print(np.diagonal(updated_weight_matrix))\\n            if updated_weight_matrix.shape==shape:\\n                return updated_weight_matrix\\n            else:\\n                raise ValueError(f'updated_weight_matrix's shape : {updated_weight_matrix.shape} is not {shape}')\\n    \\n    ### C\\n    # 교통편의성 matrix 생성\\n    C = np.asmatrix(convenience_file)\\n    \\n    ### W\\n    # Weighted Maxtrix 초기화(생성) - Identity Matrix\\n    W = update_weight_matrix()\\n    \\n    ### L\\n    # 생활인구\\n    # matrix연산 전 행정동의 순서가 제대로 되어있는지 확인 후 생활인구 Matrix 생성\\n    \\n    living_population_weekday = population_file.loc[(population_file.Covid_class==covid_class) &\\n                                           (population_file.variable==Ages)&\\n                                           (population_file.dayofweek==0),['HDNG_NM','value']]\\n\\n    living_population_weekend = population_file.loc[(population_file.Covid_class==covid_class) &\\n                                           (population_file.variable==Ages)&\\n                                           (population_file.dayofweek==1),['HDNG_NM','value']]\\n\\n    if living_population_weekday.HDNG_NM.tolist() == HDONG_ORDER:       \\n        L_1 = np.asmatrix(living_population_weekday.set_index('HDNG_NM'))\\n        L_1_shape = L_1.shape\\n    else:\\n        raise ValueError('[평일]행정동의 순서가 맞지 않습니다')\\n\\n    if living_population_weekend.HDNG_NM.tolist() == HDONG_ORDER:       \\n        L_2 = np.asmatrix(living_population_weekend.set_index('HDNG_NM'))\\n        L_2_shape = L_2.shape\\n    else:\\n        raise ValueError('[주말]행정동의 순서가 맞지 않습니다')\\n\\n    result = []\\n\\n    tmp_df = pd.DataFrame(HDONG_ORDER, columns=['HDONG_NM'])\\n    for i in range(N):        \\n        if i == 0:\\n            hdong = HDONG_ORDER[np.argmax(w1*(C*W*L_1)+w2*(C*W*L_2))]\\n            result.append(hdong)\\n        else:\\n            W = update_weight_matrix(hdong=hdong, weight_matrix=W)\\n            hdong = HDONG_ORDER[np.argmax(w1*(C*W*L_1)+w2*(C*W*L_2))]\\n            result.append(hdong)\\n        #print(pd.DataFrame(np.diagonal(W)))\\n        # tmp_df[f'W_{i}'] = np.diagonal(W)\\n        tmp_df[f'result_{i}'] = w1*(C*W*L_1) + w2*(C*W*L_2)\\n    # print(tmp_df)\\n    \\n        \\n    return result, tmp_df\\n\""
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def MCLP(dist_file, population_file, convenience_file, N=4, covid_class='A', Ages='3059', distance=3000,w1=.6,w2=.4):\n",
    "    \n",
    "    HDONG_ORDER = convenience_file.index.tolist()\n",
    "    \n",
    "    def double_power_distance_weight(df=dist_file, distance=distance):\n",
    "        shape = df.shape\n",
    "        names = df.columns.tolist()\n",
    "        flatten_values = np.concatenate(df.values)\n",
    "        weights = np.array([(1-(dist/distance)**2) if dist < distance else 0 for dist in flatten_values])\n",
    "        weights_df = pd.DataFrame(weights.reshape(shape), columns = names)\n",
    "        weights_df.index = names\n",
    "        return weights_df\n",
    "\n",
    "    def update_weight_matrix(hdong=None, weight_matrix=None, HDONG_ORDER=HDONG_ORDER):\n",
    "        shape=(34,34)\n",
    "        if not isinstance(weight_matrix, np.ndarray):\n",
    "            weight_matrix = np.diag(np.ones((34,)))\n",
    "            return weight_matrix\n",
    "        else:\n",
    "            if hdong not in HDONG_ORDER:\n",
    "                raise ValueError('hdong must be in HDONG_ORDER')\n",
    "            \n",
    "            updated_weight_matrix = weight_matrix*(1-double_power_distance_weight().loc[hdong].values)\n",
    "            # print(np.diagonal(updated_weight_matrix))\n",
    "            if updated_weight_matrix.shape==shape:\n",
    "                return updated_weight_matrix\n",
    "            else:\n",
    "                raise ValueError(f'updated_weight_matrix\\'s shape : {updated_weight_matrix.shape} is not {shape}')\n",
    "    \n",
    "    ### C\n",
    "    # 교통편의성 matrix 생성\n",
    "    C = np.asmatrix(convenience_file)\n",
    "    \n",
    "    ### W\n",
    "    # Weighted Maxtrix 초기화(생성) - Identity Matrix\n",
    "    W = update_weight_matrix()\n",
    "    \n",
    "    ### L\n",
    "    # 생활인구\n",
    "    # matrix연산 전 행정동의 순서가 제대로 되어있는지 확인 후 생활인구 Matrix 생성\n",
    "    \n",
    "    living_population_weekday = population_file.loc[(population_file.Covid_class==covid_class) &\n",
    "                                           (population_file.variable==Ages)&\n",
    "                                           (population_file.dayofweek==0),['HDNG_NM','value']]\n",
    "\n",
    "    living_population_weekend = population_file.loc[(population_file.Covid_class==covid_class) &\n",
    "                                           (population_file.variable==Ages)&\n",
    "                                           (population_file.dayofweek==1),['HDNG_NM','value']]\n",
    "\n",
    "    if living_population_weekday.HDNG_NM.tolist() == HDONG_ORDER:       \n",
    "        L_1 = np.asmatrix(living_population_weekday.set_index('HDNG_NM'))\n",
    "        L_1_shape = L_1.shape\n",
    "    else:\n",
    "        raise ValueError('[평일]행정동의 순서가 맞지 않습니다')\n",
    "\n",
    "    if living_population_weekend.HDNG_NM.tolist() == HDONG_ORDER:       \n",
    "        L_2 = np.asmatrix(living_population_weekend.set_index('HDNG_NM'))\n",
    "        L_2_shape = L_2.shape\n",
    "    else:\n",
    "        raise ValueError('[주말]행정동의 순서가 맞지 않습니다')\n",
    "\n",
    "    result = []\n",
    "\n",
    "    tmp_df = pd.DataFrame(HDONG_ORDER, columns=['HDONG_NM'])\n",
    "    for i in range(N):        \n",
    "        if i == 0:\n",
    "            hdong = HDONG_ORDER[np.argmax(w1*(C*W*L_1)+w2*(C*W*L_2))]\n",
    "            result.append(hdong)\n",
    "        else:\n",
    "            W = update_weight_matrix(hdong=hdong, weight_matrix=W)\n",
    "            hdong = HDONG_ORDER[np.argmax(w1*(C*W*L_1)+w2*(C*W*L_2))]\n",
    "            result.append(hdong)\n",
    "        #print(pd.DataFrame(np.diagonal(W)))\n",
    "        # tmp_df[f'W_{i}'] = np.diagonal(W)\n",
    "        tmp_df[f'result_{i}'] = w1*(C*W*L_1) + w2*(C*W*L_2)\n",
    "    # print(tmp_df)\n",
    "    \n",
    "        \n",
    "    return result, tmp_df\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T02:27:06.026791Z",
     "start_time": "2020-09-18T02:27:05.941021Z"
    }
   },
   "outputs": [],
   "source": [
    "def MCLP(dist_file, population_file, convenience_file, N=4, Ages='3059', distance=3000, w1=.6,w2=.4, covid_weight=[.2,.2,.2,.2,.2]):\n",
    "    \n",
    "    HDONG_ORDER = convenience_file.index.tolist()\n",
    "    \n",
    "    def double_power_distance_weight(df=dist_file, distance=distance):\n",
    "        shape = df.shape\n",
    "        names = df.columns.tolist()\n",
    "        flatten_values = np.concatenate(df.values)\n",
    "        weights = np.array([(1-(dist/distance)**2) if dist < distance else 0 for dist in flatten_values])\n",
    "        weights_df = pd.DataFrame(weights.reshape(shape), columns = names)\n",
    "        weights_df.index = names\n",
    "        return weights_df\n",
    "\n",
    "    def update_weight_matrix(hdong=None, weight_matrix=None, HDONG_ORDER=HDONG_ORDER):\n",
    "        shape=(34,34)\n",
    "        if not isinstance(weight_matrix, np.ndarray):\n",
    "            weight_matrix = np.diag(np.ones((34,)))\n",
    "            return weight_matrix\n",
    "        else:\n",
    "            if hdong not in HDONG_ORDER:\n",
    "                raise ValueError('hdong must be in HDONG_ORDER')\n",
    "            \n",
    "            updated_weight_matrix = weight_matrix*(1-double_power_distance_weight().loc[hdong].values)\n",
    "            # print(np.diagonal(updated_weight_matrix))\n",
    "            if updated_weight_matrix.shape==shape:\n",
    "                return updated_weight_matrix\n",
    "            else:\n",
    "                raise ValueError(f'updated_weight_matrix\\'s shape : {updated_weight_matrix.shape} is not {shape}')\n",
    "    \n",
    "    ### C\n",
    "    # 교통편의성 matrix 생성\n",
    "    C = np.asmatrix(convenience_file)\n",
    "    \n",
    "    ### W\n",
    "    # Weighted Maxtrix 초기화(생성) - Identity Matrix\n",
    "    W = update_weight_matrix()\n",
    "    \n",
    "    \n",
    "    \n",
    "    tmp_df = pd.DataFrame(HDONG_ORDER, columns=['HDONG_NM'])\n",
    "    result = [] \n",
    "    class_num = population_file.Covid_class.nunique()\n",
    "        \n",
    "    for i in range(N):\n",
    "        result_mat = np.zeros((34,1))\n",
    "        for covid_idx, covid_class in enumerate(population_file.Covid_class.unique()):\n",
    "            ### L\n",
    "            # 생활인구 - 코로나 정도 및 평일/주말로 구분\n",
    "            # matrix연산 전 행정동의 순서가 제대로 되어있는지 확인 후 생활인구 Matrix 생성\n",
    "            living_population_weekday = population_file.loc[(population_file.Covid_class==covid_class) &\n",
    "                                                   (population_file.variable==Ages)&\n",
    "                                                   (population_file.dayofweek==0),['HDNG_NM','value']]\n",
    "\n",
    "            living_population_weekend = population_file.loc[(population_file.Covid_class==covid_class) &\n",
    "                                                   (population_file.variable==Ages)&\n",
    "                                                   (population_file.dayofweek==1),['HDNG_NM','value']]\n",
    "\n",
    "            if living_population_weekday.HDNG_NM.tolist() == HDONG_ORDER:       \n",
    "                L_1 = np.asmatrix(living_population_weekday.set_index('HDNG_NM'))\n",
    "                L_1_shape = L_1.shape\n",
    "            else:\n",
    "                raise ValueError('[평일]행정동의 순서가 맞지 않습니다')\n",
    "\n",
    "            if living_population_weekend.HDNG_NM.tolist() == HDONG_ORDER:       \n",
    "                L_2 = np.asmatrix(living_population_weekend.set_index('HDNG_NM'))\n",
    "                L_2_shape = L_2.shape\n",
    "            else:\n",
    "                raise ValueError('[주말]행정동의 순서가 맞지 않습니다')\n",
    "\n",
    "            if i == 0:    \n",
    "                result_mat += covid_weight[covid_idx]*(w1*(C*W*L_1)+w2*(C*W*L_2))\n",
    "                if covid_idx == (class_num-1):\n",
    "                    hdong = HDONG_ORDER[np.argmax(result_mat)]\n",
    "                    result.append(hdong)\n",
    "            else:\n",
    "                if covid_idx == 0:\n",
    "                    W = update_weight_matrix(hdong=hdong, weight_matrix=W)\n",
    "                    \n",
    "                result_mat += covid_weight[covid_idx]*(w1*(C*W*L_1)+w2*(C*W*L_2))\n",
    "                if covid_idx == (class_num-1):\n",
    "                    hdong = HDONG_ORDER[np.argmax(result_mat)]\n",
    "                    result.append(hdong)\n",
    "\n",
    "            #print(pd.DataFrame(np.diagonal(W)))\n",
    "            # tmp_df[f'W_{i}'] = np.diagonal(W)\n",
    "            if covid_idx == (class_num-1):\n",
    "                tmp_df[f'result_{i}'] = result_mat\n",
    "        # print(tmp_df)\n",
    "\n",
    "        \n",
    "    return result, tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T01:52:34.838738Z",
     "start_time": "2020-09-18T01:52:34.824767Z"
    }
   },
   "outputs": [],
   "source": [
    "result, process = MCLP(real_dist, living_population, convenience_index, N=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T02:32:02.927586Z",
     "start_time": "2020-09-18T02:32:02.105618Z"
    }
   },
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "for n in [4,5,6,7,8,10]:\n",
    "    tmp_dict={}\n",
    "\n",
    "    result, process = MCLP(real_dist, living_population, convenience_index, N=n)\n",
    "    \n",
    "    tmp_dict['result'] = result\n",
    "    tmp_dict['process'] = process\n",
    "    \n",
    "    result_dict[n] = tmp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T02:33:57.698472Z",
     "start_time": "2020-09-18T02:33:57.690492Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open(os.path.join(pickle_file_path, 'result_dict.pickle'), 'wb') as f:\n",
    "#     pickle.dump(result_dict,f,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T04:11:55.107240Z",
     "start_time": "2020-09-18T04:11:54.853119Z"
    }
   },
   "outputs": [],
   "source": [
    "r,df = MCLP(real_dist, living_population, convenience_index, N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T04:15:07.204958Z",
     "start_time": "2020-09-18T04:15:07.197977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result_1   -210095.969449\n",
       "result_2   -109107.346523\n",
       "result_3    -78701.957432\n",
       "result_4    -36041.501870\n",
       "result_5    -13061.877591\n",
       "result_6    -13093.319173\n",
       "result_7    -10527.963324\n",
       "result_8     -2458.405423\n",
       "result_9     -5138.645425\n",
       "dtype: float64"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,1:].sum().diff().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T11:19:08.045346Z",
     "start_time": "2020-09-17T11:19:07.831920Z"
    }
   },
   "outputs": [],
   "source": [
    "result = {}\n",
    "\n",
    "for var in living_population.variable.unique():\n",
    "    result[var] = MCLP(real_dist, living_population, convenience_index, N=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T07:56:12.536212Z",
     "start_time": "2020-09-11T07:56:12.504123Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Adjacent Dongs: 34it [00:00, 1407.47it/s]\n"
     ]
    }
   ],
   "source": [
    "HDONGS=adjacent_dist.columns.tolist()\n",
    "adjacent_dong_dict = {}\n",
    "    \n",
    "for i,dong in tqdm(enumerate(HDONGS), desc='Finding Adjacent Dongs'):\n",
    "    adjacent_dong_dict[dong] = list(adjacent_dist.loc[adjacent_dist[dong]==0,HDONGS[i]].drop(dong).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T08:37:41.171346Z",
     "start_time": "2020-09-12T08:37:41.159848Z"
    }
   },
   "outputs": [],
   "source": [
    "pop_dict=dict(living_population.loc[(living_population.dayofweek==0) & (living_population.Covid_class=='A') & (living_population.variable=='3059')].set_index('HDNG_NM')['value'])\n",
    "conv_dict=dict(convenience_index.set_index('HDONG_NM')['conv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T05:53:06.869653Z",
     "start_time": "2020-09-12T05:53:06.865653Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T08:37:41.934922Z",
     "start_time": "2020-09-12T08:37:41.855194Z"
    }
   },
   "outputs": [],
   "source": [
    "def MCLP(dist_file, population_file, convenience_file, distance='adjacent', N=5, covid_class='A', Ages='3059'):\n",
    "    HDONGS=dist_file.columns.tolist()\n",
    "    #all_cases = list(combinations(HDONGS,N))\n",
    "    \n",
    "    # 평일 생활인구, 주말 생활인구\n",
    "    weekday_living_pop_dict = dict(population_file.loc[(population_file.dayofweek==0) & (population_file.Covid_class==covid_class) & (population_file.variable==Ages)].set_index('HDNG_NM')['value'])\n",
    "    weekend_living_pop_dict = dict(population_file.loc[(population_file.dayofweek==1) & (population_file.Covid_class==covid_class) & (population_file.variable==Ages)].set_index('HDNG_NM')['value'])\n",
    "    \n",
    "    conv_dict = dict(convenience_file.set_index(['HDONG_NM'])['conv'])\n",
    "    \n",
    "    \"\"\"\n",
    "    # case안의 행정동끼리는 인접하지 않도록 filtering\n",
    "    filtered_case = []\n",
    "    \n",
    "    for case in tqdm(all_cases, desc='Filtering Cases'):\n",
    "        if sum(sum((dist_file.loc[case,case]==0).values)) == N:\n",
    "            filtered_case.append(case)\n",
    "    \"\"\"\n",
    "    \n",
    "    #각 행정동별 인접 행정동\n",
    "    adjacent_dong_dict = {}\n",
    "    \n",
    "    for dong in tqdm(HDONGS, desc='Finding Adjacent Dongs'):\n",
    "        adjacent_dong_dict[dong] = list(dist_file.loc[dist_file[dong]==0, dong].drop(dong).index)\n",
    "    \n",
    "    weekday_HDONG = []\n",
    "    weekend_HDONG = []\n",
    "    \n",
    "    adjacent_dong_dict_copy = copy.deepcopy(adjacent_dong_dict)\n",
    "    HDONGS_copy = copy.deepcopy(HDONGS)\n",
    "    \n",
    "    for i in trange(N, desc='Getting HDONG [Weekday]'):\n",
    "        if i != 0:\n",
    "            adjacent_dong_dict_copy = {}\n",
    "            for dong in HDONGS_copy:\n",
    "                tmp_df = dist_file.loc[HDONGS_copy,HDONGS_copy]\n",
    "                adjacent_dong_dict_copy[dong] = list(tmp_df.loc[tmp_df[dong]==0, dong].drop(dong).index)\n",
    "                \n",
    "                \n",
    "        hdong = HDONGS_copy[np.argmax([weekday_living_pop_dict.get(dong) + (conv_dict.get(dong)*(sum([weekday_living_pop_dict.get(adjacent_dong) for adjacent_dong in adjacent_dongs])))\n",
    "                           for dong, adjacent_dongs in adjacent_dong_dict_copy.items()])]\n",
    "        \n",
    "        weekday_HDONG.append(hdong)\n",
    "\n",
    "        drop_dongs = adjacent_dong_dict_copy.get(hdong)\n",
    "        drop_dongs.append(hdong)\n",
    "        #print(list(adjacent_dong_dict_copy.keys()))\n",
    "        \n",
    "        for dong in drop_dongs:\n",
    "            adjacent_dong_dict_copy.pop(dong)\n",
    "            HDONGS_copy.remove(dong)\n",
    "        \n",
    "    adjacent_dong_dict_copy = copy.deepcopy(adjacent_dong_dict)\n",
    "    HDONGS_copy = copy.deepcopy(HDONGS)\n",
    "    \n",
    "    for i in trange(N, desc='Getting HDONG [Weekend]'):\n",
    "        if i != 0:\n",
    "            adjacent_dong_dict_copy = {}\n",
    "            for dong in HDONGS_copy:\n",
    "                tmp_df = dist_file.loc[HDONGS_copy,HDONGS_copy]\n",
    "                adjacent_dong_dict_copy[dong] = list(tmp_df.loc[tmp_df[dong]==0, dong].drop(dong).index)\n",
    "                \n",
    "                \n",
    "        hdong = HDONGS_copy[np.argmax([weekend_living_pop_dict.get(dong) + (conv_dict.get(dong)*(sum([weekend_living_pop_dict.get(adjacent_dong) for adjacent_dong in adjacent_dongs])))\n",
    "                           for dong, adjacent_dongs in adjacent_dong_dict_copy.items()])]\n",
    "        \n",
    "        weekend_HDONG.append(hdong)\n",
    "\n",
    "        drop_dongs = adjacent_dong_dict_copy.get(hdong)\n",
    "        drop_dongs.append(hdong)\n",
    "        #print(list(adjacent_dong_dict_copy.keys()))\n",
    "        \n",
    "        for dong in drop_dongs:\n",
    "            adjacent_dong_dict_copy.pop(dong)\n",
    "            HDONGS_copy.remove(dong)\n",
    "            \n",
    "    return weekday_HDONG, weekend_HDONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T08:37:42.625292Z",
     "start_time": "2020-09-12T08:37:42.217328Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Adjacent Dongs: 100%|████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 1045.08it/s]\n",
      "Getting HDONG [Weekday]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 24.82it/s]\n",
      "Getting HDONG [Weekend]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 21.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['신당동', '명동', '월계3동', '상계2동'], ['신당동', '월계3동', '명동', '상계2동'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MCLP(adjacent_dist, living_population, convenience_index,Ages='60U', N=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T08:37:47.839696Z",
     "start_time": "2020-09-12T08:37:47.527864Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Adjacent Dongs: 100%|█████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 895.86it/s]\n",
      "Getting HDONG [Weekday]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 27.93it/s]\n",
      "Getting HDONG [Weekend]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 36.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['신당동', '명동', '월계3동', '상계2동'], ['신당동', '월계3동', '명동', '상계2동'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MCLP(adjacent_dist, living_population, convenience_index, N=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T08:37:48.422838Z",
     "start_time": "2020-09-12T08:37:48.049912Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Adjacent Dongs: 100%|█████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 653.41it/s]\n",
      "Getting HDONG [Weekday]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 26.70it/s]\n",
      "Getting HDONG [Weekend]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 29.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['신당동', '명동', '월계3동', '하계1동'], ['신당동', '월계3동', '명동', '하계1동'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MCLP(adjacent_dist, living_population, convenience_index,Ages='30L', N=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T11:17:09.376137Z",
     "start_time": "2020-09-12T11:17:06.480492Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Adjacent Dongs: 100%|████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 1623.31it/s]\n",
      "Getting HDONG [Weekday]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 50.16it/s]\n",
      "Getting HDONG [Weekend]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 50.75it/s]\n",
      "Finding Adjacent Dongs: 100%|████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 1707.64it/s]\n",
      "Getting HDONG [Weekday]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 49.49it/s]\n",
      "Getting HDONG [Weekend]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 47.73it/s]\n",
      "Finding Adjacent Dongs: 100%|████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 1704.45it/s]\n",
      "Getting HDONG [Weekday]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 50.13it/s]\n",
      "Getting HDONG [Weekend]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 49.49it/s]\n",
      "Finding Adjacent Dongs: 100%|████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 1704.55it/s]\n",
      "Getting HDONG [Weekday]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 49.73it/s]\n",
      "Getting HDONG [Weekend]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 50.42it/s]\n",
      "Finding Adjacent Dongs: 100%|████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 1704.41it/s]\n",
      "Getting HDONG [Weekday]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 50.11it/s]\n",
      "Getting HDONG [Weekend]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 50.77it/s]\n",
      "Finding Adjacent Dongs: 100%|████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 1797.68it/s]\n",
      "Getting HDONG [Weekday]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 48.30it/s]\n",
      "Getting HDONG [Weekend]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 48.82it/s]\n",
      "Finding Adjacent Dongs: 100%|████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 1623.44it/s]\n",
      "Getting HDONG [Weekday]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 48.72it/s]\n",
      "Getting HDONG [Weekend]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 49.78it/s]\n",
      "Finding Adjacent Dongs: 100%|████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 1623.39it/s]\n",
      "Getting HDONG [Weekday]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 51.42it/s]\n",
      "Getting HDONG [Weekend]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 51.40it/s]\n",
      "Finding Adjacent Dongs: 100%|████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 1701.60it/s]\n",
      "Getting HDONG [Weekday]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 48.28it/s]\n",
      "Getting HDONG [Weekend]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 48.30it/s]\n",
      "Finding Adjacent Dongs: 100%|████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 1684.54it/s]\n",
      "Getting HDONG [Weekday]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 48.91it/s]\n",
      "Getting HDONG [Weekend]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 49.52it/s]\n",
      "Finding Adjacent Dongs: 100%|████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 1701.81it/s]\n",
      "Getting HDONG [Weekday]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 48.34it/s]\n",
      "Getting HDONG [Weekend]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 50.15it/s]\n",
      "Finding Adjacent Dongs: 100%|████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 1620.86it/s]\n",
      "Getting HDONG [Weekday]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 48.28it/s]\n",
      "Getting HDONG [Weekend]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 50.75it/s]\n",
      "Finding Adjacent Dongs: 100%|████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 1706.25it/s]\n",
      "Getting HDONG [Weekday]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 48.89it/s]\n",
      "Getting HDONG [Weekend]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 48.32it/s]\n",
      "Finding Adjacent Dongs: 100%|████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 1622.96it/s]\n",
      "Getting HDONG [Weekday]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 49.50it/s]\n",
      "Getting HDONG [Weekend]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 50.71it/s]\n",
      "Finding Adjacent Dongs: 100%|████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 1794.02it/s]\n",
      "Getting HDONG [Weekday]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 49.83it/s]\n",
      "Getting HDONG [Weekend]: 100%|███████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 50.36it/s]\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "for class_ in living_population.Covid_class.unique():\n",
    "    for var in living_population.variable.unique():\n",
    "        result[(class_,var)] = MCLP(adjacent_dist, living_population, convenience_index, Ages=var, covid_class=class_, N=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T11:17:13.278404Z",
     "start_time": "2020-09-12T11:17:13.273417Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('A', '3059'): (['신당동', '명동', '월계3동', '상계2동'], ['신당동', '월계3동', '명동', '상계2동']),\n",
       " ('A', '30L'): (['신당동', '명동', '월계3동', '하계1동'], ['신당동', '월계3동', '명동', '하계1동']),\n",
       " ('A', '60U'): (['신당동', '명동', '월계3동', '상계2동'], ['신당동', '월계3동', '명동', '상계2동']),\n",
       " ('B', '3059'): (['신당동', '명동', '월계3동', '상계2동'], ['신당동', '월계3동', '명동', '상계2동']),\n",
       " ('B', '30L'): (['신당동', '월계3동', '명동', '하계1동'], ['신당동', '월계3동', '명동', '하계1동']),\n",
       " ('B', '60U'): (['신당동', '명동', '월계3동', '상계2동'], ['신당동', '월계3동', '명동', '상계2동']),\n",
       " ('C', '3059'): (['신당동', '명동', '월계3동', '상계2동'], ['신당동', '월계3동', '명동', '상계2동']),\n",
       " ('C', '30L'): (['신당동', '월계3동', '명동', '하계1동'], ['신당동', '월계3동', '명동', '하계1동']),\n",
       " ('C', '60U'): (['신당동', '명동', '월계3동', '상계2동'], ['신당동', '월계3동', '명동', '상계2동']),\n",
       " ('D', '3059'): (['신당동', '명동', '월계3동', '상계2동'], ['신당동', '월계3동', '명동', '상계2동']),\n",
       " ('D', '30L'): (['신당동', '월계3동', '명동', '하계1동'], ['신당동', '월계3동', '명동', '하계1동']),\n",
       " ('D', '60U'): (['신당동', '명동', '월계3동', '상계2동'], ['신당동', '월계3동', '명동', '상계2동']),\n",
       " ('E', '3059'): (['신당동', '명동', '월계3동', '상계2동'], ['신당동', '월계3동', '명동', '상계2동']),\n",
       " ('E', '30L'): (['신당동', '월계3동', '명동', '하계1동'], ['신당동', '월계3동', '명동', '하계1동']),\n",
       " ('E', '60U'): (['신당동', '명동', '월계3동', '상계2동'], ['신당동', '월계3동', '명동', '상계2동'])}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T12:36:40.098634Z",
     "start_time": "2020-09-15T12:36:40.094240Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp_dict = {dong:0 for dong in adjacent_dist.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T12:37:12.986376Z",
     "start_time": "2020-09-15T12:37:12.978398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['공릉1동',\n",
       " '공릉2동',\n",
       " '상계10동',\n",
       " '상계1동',\n",
       " '상계2동',\n",
       " '상계3.4동',\n",
       " '상계5동',\n",
       " '상계6.7동',\n",
       " '상계8동',\n",
       " '상계9동',\n",
       " '월계1동',\n",
       " '월계2동',\n",
       " '월계3동',\n",
       " '중계1동',\n",
       " '중계2.3동',\n",
       " '중계4동',\n",
       " '중계본동',\n",
       " '하계1동',\n",
       " '하계2동',\n",
       " '광희동',\n",
       " '다산동',\n",
       " '동화동',\n",
       " '명동',\n",
       " '소공동',\n",
       " '신당5동',\n",
       " '신당동',\n",
       " '약수동',\n",
       " '을지로동',\n",
       " '장충동',\n",
       " '중림동',\n",
       " '청구동',\n",
       " '필동',\n",
       " '황학동',\n",
       " '회현동']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[key for key,val in tmp_dict.items() if val==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T12:28:27.032959Z",
     "start_time": "2020-09-15T12:28:27.019495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['소공동', '을지로동', '필동', '회현동']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(adjacent_dist.loc[adjacent_dist['명동']==0, '명동'].drop('명동').index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCLP(dist_file, population_file, convenience_file, distance='adjacent', N=5, covid_class='A', Ages='3059'):\n",
    "    HDONGS=dist_file.columns.tolist()\n",
    "    \n",
    "    # 평일 생활인구, 주말 생활인구\n",
    "    weekday_living_pop_dict = dict(population_file.loc[(population_file.dayofweek==0) & (population_file.Covid_class==covid_class) & (population_file.variable==Ages)].set_index('HDNG_NM')['value'])\n",
    "    weekend_living_pop_dict = dict(population_file.loc[(population_file.dayofweek==1) & (population_file.Covid_class==covid_class) & (population_file.variable==Ages)].set_index('HDNG_NM')['value'])\n",
    "    \n",
    "    conv_dict = dict(convenience_file.set_index(['HDONG_NM'])['conv'])\n",
    "    \n",
    "    considered_dong = {dong:0 for dong in HDONGS}\n",
    "    \n",
    "    \"\"\"\n",
    "    # case안의 행정동끼리는 인접하지 않도록 filtering\n",
    "    filtered_case = []\n",
    "    \n",
    "    for case in tqdm(all_cases, desc='Filtering Cases'):\n",
    "        if sum(sum((dist_file.loc[case,case]==0).values)) == N:\n",
    "            filtered_case.append(case)\n",
    "    \"\"\"\n",
    "    \n",
    "    #각 행정동별 인접 행정동\n",
    "    adjacent_dong_dict = {}\n",
    "    \n",
    "    for dong in tqdm(HDONGS, desc='Finding Adjacent Dongs'):\n",
    "        adjacent_dong_dict[dong] = list(dist_file.loc[dist_file[dong]==0, dong].drop(dong).index)\n",
    "    \n",
    "    weekday_HDONG = []\n",
    "    weekend_HDONG = []\n",
    "    \n",
    "    adjacent_dong_dict_copy = copy.deepcopy(adjacent_dong_dict)\n",
    "    HDONGS_copy = copy.deepcopy(HDONGS)\n",
    "    \n",
    "    for i in trange(N, desc='Getting HDONG [Weekday]'):\n",
    "        not_considered = [dong for dong,considered in considered_dong.items() if considered==0]\n",
    "        hdong = HDONGS_copy[np.argmax()]\n",
    "    \n",
    "    \n",
    "    for i in trange(N, desc='Getting HDONG [Weekday]'):\n",
    "        if i != 0:\n",
    "            adjacent_dong_dict_copy = {}\n",
    "            for dong in HDONGS_copy:\n",
    "                tmp_df = dist_file.loc[HDONGS_copy,HDONGS_copy]\n",
    "                adjacent_dong_dict_copy[dong] = list(tmp_df.loc[tmp_df[dong]==0, dong].drop(dong).index)\n",
    "                \n",
    "                \n",
    "        hdong = HDONGS_copy[np.argmax([weekday_living_pop_dict.get(dong) + (conv_dict.get(dong)*(sum([weekday_living_pop_dict.get(adjacent_dong) for adjacent_dong in adjacent_dongs])))\n",
    "                           for dong, adjacent_dongs in adjacent_dong_dict_copy.items()])]\n",
    "        \n",
    "        weekday_HDONG.append(hdong)\n",
    "\n",
    "        drop_dongs = adjacent_dong_dict_copy.get(hdong)\n",
    "        drop_dongs.append(hdong)\n",
    "        #print(list(adjacent_dong_dict_copy.keys()))\n",
    "        \n",
    "        for dong in drop_dongs:\n",
    "            adjacent_dong_dict_copy.pop(dong)\n",
    "            HDONGS_copy.remove(dong)\n",
    "        \n",
    "    adjacent_dong_dict_copy = copy.deepcopy(adjacent_dong_dict)\n",
    "    HDONGS_copy = copy.deepcopy(HDONGS)\n",
    "    \n",
    "    for i in trange(N, desc='Getting HDONG [Weekend]'):\n",
    "        if i != 0:\n",
    "            adjacent_dong_dict_copy = {}\n",
    "            for dong in HDONGS_copy:\n",
    "                tmp_df = dist_file.loc[HDONGS_copy,HDONGS_copy]\n",
    "                adjacent_dong_dict_copy[dong] = list(tmp_df.loc[tmp_df[dong]==0, dong].drop(dong).index)\n",
    "                \n",
    "                \n",
    "        hdong = HDONGS_copy[np.argmax([weekend_living_pop_dict.get(dong) + (conv_dict.get(dong)*(sum([weekend_living_pop_dict.get(adjacent_dong) for adjacent_dong in adjacent_dongs])))\n",
    "                           for dong, adjacent_dongs in adjacent_dong_dict_copy.items()])]\n",
    "        \n",
    "        weekend_HDONG.append(hdong)\n",
    "\n",
    "        drop_dongs = adjacent_dong_dict_copy.get(hdong)\n",
    "        drop_dongs.append(hdong)\n",
    "        #print(list(adjacent_dong_dict_copy.keys()))\n",
    "        \n",
    "        for dong in drop_dongs:\n",
    "            adjacent_dong_dict_copy.pop(dong)\n",
    "            HDONGS_copy.remove(dong)\n",
    "            \n",
    "    return weekday_HDONG, weekend_HDONG"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
